# ğŸ¤Ÿ Sign Language Detector

A full-stack web application that helps detect and translate sign language gestures into text or speech. This project aims to bridge communication gaps for the hearing and speech impaired using computer vision and deep learning.

---

## ğŸš€ Features

- ğŸ– Real-time hand gesture recognition
- ğŸ“· Webcam-based input
- ğŸ§  Deep learning / ML-powered detection (Mediapipe / Jax)
- ğŸ“„ Text output for each gesture
- ğŸ”Š Optional speech output (TTS integration)
- ğŸ§© Clean separation of frontend and backend
- ğŸŒ Cross-platform browser support

---

## ğŸ§° Tech Stack

### Frontend:
- âš› React.js
- ğŸ’… CSS / Styled-components
- ğŸ“¦ Axios (API requests)

### Backend:
- ğŸ Python (Flask)
- ğŸ”¬ Mediapipe (gesture detection)
- ğŸ“Š JAX / JAXlib (if used)
- ğŸŒ Flask-CORS

### Tools:
- ğŸ”§ Node.js / npm
- ğŸ™ Git & GitHub
- ğŸ“ Virtualenv

---

## ğŸ“‚ Project Structure
Sign_lang_Project/
â”œâ”€â”€ frontend/ â†’ React-based UI
â””â”€â”€ backend/ â†’ Flask + Mediapipe API
