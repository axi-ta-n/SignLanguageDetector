# 🤟 Sign Language Detector

A full-stack web application that helps detect and translate sign language gestures into text or speech. This project aims to bridge communication gaps for the hearing and speech impaired using computer vision and deep learning.

---

## 🚀 Features

- 🖐 Real-time hand gesture recognition
- 📷 Webcam-based input
- 🧠 Deep learning / ML-powered detection (Mediapipe / Jax)
- 📄 Text output for each gesture
- 🔊 Optional speech output (TTS integration)
- 🧩 Clean separation of frontend and backend
- 🌐 Cross-platform browser support

---

## 🧰 Tech Stack

### Frontend:
- ⚛ React.js
- 💅 CSS / Styled-components
- 📦 Axios (API requests)

### Backend:
- 🐍 Python (Flask)
- 🔬 Mediapipe (gesture detection)
- 📊 JAX / JAXlib (if used)
- 🌐 Flask-CORS

### Tools:
- 🔧 Node.js / npm
- 🐙 Git & GitHub
- 📁 Virtualenv

---

## 📂 Project Structure
Sign_lang_Project/
├── frontend/ → React-based UI
└── backend/ → Flask + Mediapipe API
